# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.211.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "mapping.baml": "// Column mapping function for ImportCSV\n\n// Input types\nclass UploadColumn {\n  index int\n  name string\n  sample string?  // Optional sample data\n}\n\nclass TemplateColumn {\n  key string\n  name string\n  required bool\n}\n\n// Output types\nclass ColumnMapping {\n  upload_index int\n  template_key string\n  confidence float @description(\"Confidence score from 0 to 1\")\n}\n\nclass MappingResult {\n  mappings ColumnMapping[]\n}\n\n// Main mapping function\nfunction MapColumns(\n  upload_columns: UploadColumn[],\n  template_columns: TemplateColumn[]\n) -> MappingResult {\n  client \"openai/gpt-5.2\"\n  prompt #\"\n    Map CSV columns to template fields based on names and sample data.\n\n    CSV columns:\n    {{ upload_columns }}\n\n    Template fields:\n    {{ template_columns }}\n\n    Rules:\n    - EXACT MATCH PRIORITY: If a CSV column name exactly matches a template field name\n      (ignoring case, underscores, spaces), ALWAYS map it with confidence 1.0\n    - When multiple CSV columns contain similar words (e.g., \"Email\", \"Email consent\",\n      \"Email subscription\"), prefer the SHORTEST/most specific column name for the base field\n    - Use sample data to validate matches:\n      - Email fields should contain \"@\" symbols\n      - Date fields should contain date-like values\n      - Boolean/consent fields typically contain yes/no/true/false\n    - Only include mappings with confidence > 0.8\n    - Each template field can only be mapped once\n    - Each CSV column can only be mapped once\n\n    Example: Given columns [\"Email consent\", \"Email subscription status\", \"Email\"] and\n    template field \"email\", map \"Email\" (index 2) because it's an exact match, NOT\n    \"Email consent\" which is a different concept (consent flag, not email address).\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test case\ntest map_basic_columns {\n  functions [MapColumns]\n  args {\n    upload_columns [\n      { index 0, name \"Email Address\", sample \"john@example.com\" },\n      { index 1, name \"Full Name\", sample \"John Doe\" },\n      { index 2, name \"Phone\", sample \"555-1234\" }\n    ]\n    template_columns [\n      { key \"email\", name \"Email\", required true },\n      { key \"name\", name \"Name\", required true },\n      { key \"phone\", name \"Phone Number\", required false }\n    ]\n  }\n}\n\n// Test case for exact match priority (Issue #15)\n// \"Email\" column should map to \"email\" field, NOT \"Email consent\"\ntest map_email_vs_email_consent {\n  functions [MapColumns]\n  args {\n    upload_columns [\n      { index 0, name \"Email consent\", sample \"yes\" },\n      { index 1, name \"Email subscription status\", sample \"active\" },\n      { index 2, name \"Email opt-in date\", sample \"2024-01-15\" },\n      { index 3, name \"Email\", sample \"john@example.com\" },\n      { index 4, name \"First Name\", sample \"John\" }\n    ]\n    template_columns [\n      { key \"email\", name \"Email\", required true },\n      { key \"first_name\", name \"First Name\", required true }\n    ]\n  }\n}\n",
    "schema.baml": "// Schema inference from CSV sample data\n\nclass SampleColumn {\n    name string @description(\"Column header name from CSV\")\n    samples string[] @description(\"5-10 sample values from the column\")\n}\n\nenum ColumnType {\n    Text\n    Email\n    Phone\n    Date\n    Number\n    Boolean\n    Select\n}\n\nclass InferredColumn {\n    name string @description(\"Original column name\")\n    display_name string @description(\"Human-readable display name\")\n    type ColumnType @description(\"Inferred data type\")\n    confidence float @description(\"Confidence score 0-1\")\n    suggested_options string[]? @description(\"For select type: detected unique values\")\n    reasoning string @description(\"Brief explanation of why this type was chosen\")\n}\n\nclass InferredSchema {\n    columns InferredColumn[]\n}\n\nfunction InferSchema(columns: SampleColumn[]) -> InferredSchema {\n    client CustomGPT4oMini\n    prompt #\"\n        Analyze these CSV columns and infer the best data type for each.\n\n        Rules:\n        - email: Values look like email addresses (contain @ and domain)\n        - phone: Values look like phone numbers (digits, dashes, parentheses, +)\n        - date: Values look like dates (various formats: YYYY-MM-DD, MM/DD/YYYY, etc.)\n        - number: Values are numeric (integers, decimals, currency amounts)\n        - boolean: Values are binary (true/false, yes/no, 1/0, active/inactive)\n        - select: Low cardinality (â‰¤10 unique values) with repeated patterns\n        - text: Default for everything else\n\n        For display_name, convert snake_case/kebab-case to Title Case.\n        For select types, include the unique values as suggested_options.\n\n        Columns to analyze:\n        {% for col in columns %}\n        Column: {{ col.name }}\n        Samples: {{ col.samples | join(\", \") }}\n        {% endfor %}\n\n        {{ ctx.output_format }}\n    \"#\n}\n",
    "transformation.baml": "// Data transformation functions for ImportCSV\n\n// ============== Data Models ==============\n\n// Validation rule structure for different data types\nclass ValidationRule {\n  error_type string  // The error message type (e.g., \"email must be a valid email address\")\n  type string\n  rule string\n  pattern string?\n  regex string?  // Actual regex pattern used for validation\n  regex_description string?  // Human-readable description of the regex\n  valid_examples string[]\n  invalid_examples string[]\n  common_fixes map<string, string>\n}\n\n// Error information from validation\nclass ValidationError {\n  row_index int\n  column_key string\n  value string\n  error_message string\n}\n\n// Row data structure\nclass RowData {\n  row_index int\n  data map<string, string>\n}\n\n// Single transformation\nclass Transformation {\n  row_index int\n  column string\n  old_value string\n  new_value string\n  confidence float\n}\n\n// Result containing all transformations\nclass TransformationResult {\n  transformations Transformation[]\n}\n\n// ============== Functions ==============\n\n// Function to identify relevant columns for transformation\nfunction IdentifyRelevantColumns(\n  prompt: string,\n  available_columns: string[]\n) -> string[] {\n  client \"openai/gpt-4.1\"\n  prompt #\"\n    Given this user request: \"{{ prompt }}\"\n    And these available columns: {{ available_columns }}\n\n    Which columns are relevant for this transformation?\n\n    Return ONLY the column names that are needed for the requested transformation.\n    Be selective - only include columns that are directly relevant.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Main function to fix validation errors with structured rules\n// Note: validation_rules are passed from Python based on the error types detected\n// No additional LLM call needed - rules are predefined in the application\nfunction FixValidationErrors(\n  user_prompt: string,\n  validation_errors: ValidationError[],\n  row_data: RowData[],\n  validation_rules: ValidationRule[]  // Changed from map to array\n) -> TransformationResult {\n  client \"openai/gpt-4.1\"\n  prompt #\"\n    Fix ONLY these rows with validation errors:\n\n    Errors to fix:\n    {{ validation_errors }}\n\n    Data for error rows:\n    {{ row_data }}\n\n    VALIDATION RULES:\n    {% for rule in validation_rules %}\n    For '{{ rule.error_type }}':\n    - Rule: {{ rule.rule }}\n    - Pattern: {{ rule.pattern }}\n    {% if rule.regex %}\n    - Regex Pattern: {{ rule.regex }}\n    - Format Description: {{ rule.regex_description }}\n    {% endif %}\n    - Valid examples: {{ rule.valid_examples }}\n    - Invalid examples: {{ rule.invalid_examples }}\n    - Common fixes: {{ rule.common_fixes }}\n    {% endfor %}\n\n    User request: {{ user_prompt }}\n\n    IMPORTANT:\n    - ONLY fix the rows listed above\n    - Each row should be fixed according to its error message and validation rules\n    - Return transformations ONLY for rows with errors\n    - Do NOT change any other rows\n    - You MUST fix ALL {{ validation_errors | length }} rows listed in the errors above\n    - Generate exactly {{ validation_errors | length }} transformations, one for each error\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// General transformation function for data without validation errors\nfunction TransformDataGeneral(\n  user_prompt: string,\n  row_data: RowData[]\n) -> TransformationResult {\n  client \"openai/gpt-4.1\"\n  prompt #\"\n    Transform this data according to the user's request.\n\n    User request: {{ user_prompt }}\n\n    Data to transform:\n    {{ row_data }}\n\n    Return transformations for the data based on the user's request.\n    Be confident in your transformations and set confidence scores appropriately.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// ============== Test Cases ==============\n\n// Test the function with a sample transformation request\ntest identify_email_columns {\n  functions [IdentifyRelevantColumns]\n  args {\n    prompt \"Fix all email addresses with an error\"\n    available_columns [\n      \"name\",\n      \"email\",\n      \"phone\",\n      \"address\",\n      \"city\",\n      \"state\",\n      \"zip\",\n      \"country\",\n      \"date_joined\",\n      \"last_login\"\n    ]\n  }\n}\n\n",
}

def get_baml_files():
    return _file_map